
       ?
4 2 3 5        0 0 1 0         4 2 3 5
1 4 4 2     -  1 0 0 0    *    1 4 4 2
3 4 5 1        0 0 0 1         3 4 5 1

8 10 12 8     0 0 3 0 
8 10 12 8  -  1 0 0 0
8 10 12 8     0 0 0 1

8 10 8  9
7 10 12 8
8 10 12 7


1 1 1  *  4 1 3 5      8 10 12 8     
1 1 1  *  1 4 4 2   =  8 10 12 8
1 1 1  *  3 4 5 1      8 10 12 8


each row of W:
D = 8, N = 3, C = 4
W: DxC, X: NxD


1 6 3 7 2 3 3 7
4 3 7 6 1 1 7 2
5 5 6 6 4 8 7 2 
2 6 2 6 2 8 4 7


so for each 3 rows of X

dot-multiply each of the 8 columns of W by X, add these up. 
multiply that result by 



Try again...

for w_y[i]'s:


D = 8, N = 5, C = 4

one-hot y   gradient additive weighted X   
0 0 1 0     4 2 3 5 7 1 8 2
1 0 0 0     1 4 4 2 5 6 8 3
0 0 0 1     3 2 7 4 8 1 3 2
1 0 0 0     4 3 6 6 1 7 2 5
0 1 0 0     9 8 2 5 3 7 1 8

4 1 3 4 9   0 0 1 0            5 9 4 3
2 4 2 3 8   1 0 0 0            7 8 2 2
3 4 7 6 2   0 0 0 1    =     etc        :)?     so: np.dot(X.T, one-hot.)
5 2 4 6 5   1 0 0 0
7 5 8 1 3   0 1 0 0
1 6 1 7 7
8 8 3 2 1
2 3 2 5 8


to get:

1+4=5  9 4 3
4+3=7  8 2 2
4+6=10 2 3 7
2+6=8  5 5 4
5+1=6  3 7 8
6+7=13 7 1 1
8+2=10 1 8 3
4+5=9  8 2 2



for w_~y[i]'s:

one-hot y   gradient non-additive weighted X   (nevermind that they are the same as)
0 0 1 0     4 2 3 5 7 1 8 2
1 0 0 0     1 4 4 2 5 6 8 3
0 0 0 1     3 2 7 4 8 1 3 2
1 0 0 0     4 3 6 6 1 7 2 5
0 1 0 0     9 8 2 5 3 7 1 8



to get: just use inverse of one-hot-y. BUT: to get that non-additive weighted x...


one-hot-y is NxC. for each C, 





4 1 3 4 9   0 0 1 0            5 9 4 3
2 4 2 3 8   1 0 0 0            7 8 2 2
3 4 7 6 2   0 0 0 1    =     etc        :)?     so: np.dot(X.T, one-hot.)
5 2 4 6 5   1 0 0 0
7 5 8 1 3   0 1 0 0
1 6 1 7 7
8 8 3 2 1
2 3 2 5 8


to get:

1+4=5  9 4 3
4+3=7  8 2 2
4+6=10 2 3 7
2+6=8  5 5 4
5+1=6  3 7 8
6+7=13 7 1 1
8+2=10 1 8 3
4+5=9  8 2 2




